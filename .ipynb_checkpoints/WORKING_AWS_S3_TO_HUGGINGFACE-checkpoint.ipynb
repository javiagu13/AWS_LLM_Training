{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5523855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install boto3 huggingface_hub tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home directory is: C:\\Users\\javia\n",
      "Downloading model from S3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.tar.gz:  59%|█████████████████████████████▉                     | 8.65G/14.7G [37:13<16:44, 6.06MB/s]"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "import os\n",
    "import sys\n",
    "from huggingface_hub import HfApi, HfFolder, upload_folder\n",
    "from tqdm import tqdm  # For the progress bar\n",
    "\n",
    "def main():\n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # S3 bucket and key\n",
    "    bucket_name = 'llama-training-s3'\n",
    "    s3_key = 'llama-training-s3/model/pytorch-training-2025-01-20-06-15-03-149/output/model.tar.gz'\n",
    "\n",
    "    # Use the home directory for storage\n",
    "    home_dir = os.path.expanduser('~')\n",
    "    print(\"Home directory is:\", home_dir)\n",
    "\n",
    "    # Define local paths using the home directory\n",
    "    local_model_tar = os.path.join(home_dir, 'model.tar.gz')\n",
    "    model_dir = os.path.join(home_dir, 'llama31-testloss-pcliner')\n",
    "\n",
    "    # Get the size of the file to download\n",
    "    try:\n",
    "        response = s3.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "        total_length = response.get('ContentLength')\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving object metadata from S3: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Download model.tar.gz from S3 with progress bar\n",
    "    print(\"Downloading model from S3...\")\n",
    "    try:\n",
    "        with tqdm(total=total_length, unit='B', unit_scale=True, desc='Downloading model.tar.gz') as pbar:\n",
    "            def progress_hook(bytes_amount):\n",
    "                pbar.update(bytes_amount)\n",
    "\n",
    "            s3.download_file(\n",
    "                Bucket=bucket_name,\n",
    "                Key=s3_key,\n",
    "                Filename=local_model_tar,\n",
    "                Callback=progress_hook\n",
    "            )\n",
    "        print(f\"Downloaded model.tar.gz to {local_model_tar}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file from S3: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Extract the tar.gz file\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Extracting model files...\")\n",
    "    try:\n",
    "        with tarfile.open(local_model_tar, 'r:gz') as tar:\n",
    "            tar.extractall(path=model_dir)\n",
    "        print(f\"Extracted model to {model_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting model files: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Set up Hugging Face API\n",
    "    # Set up Hugging Face API\n",
    "    hf_token = \"WRITE_YOUR_HF_TOKEN\"  # Replace with your actual token\n",
    "    HfFolder.save_token(hf_token)\n",
    "\n",
    "    username = \"javiagu\"  # Replace with your Hugging Face username\n",
    "    model_name = \"gemma2_pCliNER_bf16\"  # Replace with your desired model name\n",
    "    model_repo_id = f\"{username}/{model_name}\"\n",
    "\n",
    "    api = HfApi()\n",
    "\n",
    "    # Create the repository (if it doesn't exist)\n",
    "    try:\n",
    "        api.create_repo(\n",
    "            repo_id=model_repo_id,\n",
    "            repo_type=\"model\",\n",
    "            exist_ok=True,\n",
    "            token=hf_token\n",
    "        )\n",
    "        print(f\"Repository {model_repo_id} is ready.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating repository on Hugging Face Hub: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Upload the model files\n",
    "    print(\"Uploading model to Hugging Face Hub...\")\n",
    "    try:\n",
    "        upload_folder(\n",
    "            folder_path=model_dir,\n",
    "            repo_id=model_repo_id,\n",
    "            repo_type=\"model\",\n",
    "            token=hf_token,\n",
    "            ignore_patterns=[\"*.ipynb_checkpoints\", \"*.lock\"],\n",
    "        )\n",
    "        print(\"Model uploaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading model to Hugging Face Hub: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d4e6d",
   "metadata": {},
   "source": [
    "CONTENT CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_extracted_files(directory):\n",
    "    \"\"\"\n",
    "    List all files and their sizes in a given directory.\n",
    "    \"\"\"\n",
    "    print(f\"{'File/Folder':<80} {'Size (Bytes)':>15}\")\n",
    "    print(\"-\" * 95)\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(root, name)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"{file_path:<80} {file_size:>15}\")\n",
    "\n",
    "    print(\"\\nListing completed.\")\n",
    "\n",
    "# Directory containing the extracted files\n",
    "model_dir = os.path.join(os.path.expanduser('~'), 'model')\n",
    "\n",
    "# Check if the directory exists before listing files\n",
    "if os.path.exists(model_dir):\n",
    "    print(f\"Listing contents of extracted directory: {model_dir}\")\n",
    "    list_extracted_files(model_dir)\n",
    "else:\n",
    "    print(f\"Directory {model_dir} does not exist. Extraction might have failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01432ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Hugging Face API\n",
    "# Set up Hugging Face API\n",
    "hf_token = \"WRITE_YOUR_HF_TOKEN\"  # Replace with your actual token\n",
    "HfFolder.save_token(hf_token)\n",
    "\n",
    "username = \"javiagu\"  # Replace with your Hugging Face username\n",
    "model_name = \"KULLM_pCliNER_bf16\"  # Replace with your desired model name\n",
    "model_repo_id = f\"{username}/{model_name}\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create the repository (if it doesn't exist)\n",
    "try:\n",
    "    api.create_repo(\n",
    "        repo_id=model_repo_id,\n",
    "        repo_type=\"model\",\n",
    "        exist_ok=True,\n",
    "        token=hf_token\n",
    "    )\n",
    "    print(f\"Repository {model_repo_id} is ready.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating repository on Hugging Face Hub: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Upload the model files\n",
    "print(\"Uploading model to Hugging Face Hub...\")\n",
    "try:\n",
    "    upload_folder(\n",
    "        folder_path=model_dir,\n",
    "        repo_id=model_repo_id,\n",
    "        repo_type=\"model\",\n",
    "        token=hf_token,\n",
    "        ignore_patterns=[\"*.ipynb_checkpoints\", \"*.lock\"],\n",
    "    )\n",
    "    print(\"Model uploaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading model to Hugging Face Hub: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Clean up local files\n",
    "print(\"Cleaning up local files...\")\n",
    "try:\n",
    "    os.remove(local_model_tar)\n",
    "    import shutil\n",
    "    shutil.rmtree(model_dir)\n",
    "    print(\"Clean up completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during clean up: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
